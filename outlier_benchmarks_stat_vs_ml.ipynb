{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Outlier Detection on Benchmarks (Statistical vs ML)\n",
        "\n",
        "This notebook runs **outlier detection** on several `pymoo` benchmark problems using two families of methods:\n",
        "\n",
        "- **StatisticalOutlierDetection**: Z-Score, IQR, Leverage, Cook's Distance, Mahalanobis Distance\n",
        "- **MLOutlierDetection**: Elliptic Envelope, Isolation Forest, Local Outlier Factor, One-Class SVM, SGD One-Class SVM\n",
        "\n",
        "For each benchmark we:\n",
        "1. Generate a **Latin Hypercube Sampling (LHS)** Design of Experiments (DoE)\n",
        "2. Evaluate the problem to get the target `y`\n",
        "3. **Inject output outliers** into `y` (5%)\n",
        "4. Run statistical methods (mostly on `y` or joint `[X, y]`) and ML methods (on **augmented features** `[X, y]` to capture output anomalies)\n",
        "5. Report **Precision, Recall, F1-score, ROC-AUC** and draw the **ROC curve** with `RocCurveDisplay`\n",
        "\n",
        "> Note: Since we inject outliers in **Y**, ML methods are run on the augmented feature set `[X, y_noisy]` so they can learn the joint pattern and flag inconsistencies in the output.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "from sklearn.covariance import EmpiricalCovariance, EllipticEnvelope\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.linear_model import SGDOneClassSVM, LinearRegression\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, RocCurveDisplay\n",
        "from scipy.stats import qmc\n",
        "from pymoo.problems import get_problem\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Benchmark:\n",
        "    def __init__(self, name: str, dim: int = None):\n",
        "        self.name = name.lower()\n",
        "        self.dim = dim\n",
        "        \n",
        "        if self.name == \"rosenbrock\":\n",
        "            if self.dim is None:\n",
        "                raise ValueError(\"Set dim for Rosenbrock\")\n",
        "            self.problem = get_problem(\"rosenbrock\", n_var=self.dim)\n",
        "        elif self.name == \"kursawe\":\n",
        "            self.problem = get_problem(\"kursawe\")\n",
        "            self.dim = self.problem.n_var\n",
        "        elif self.name == \"sphere\":\n",
        "            if self.dim is None:\n",
        "                self.dim = 2\n",
        "            self.problem = get_problem(\"sphere\", n_var=self.dim)\n",
        "        else:\n",
        "            self.problem = get_problem(self.name, n_var=self.dim)\n",
        "            if self.dim is None:\n",
        "                self.dim = self.problem.n_var\n",
        "        \n",
        "        self.bounds = np.vstack([self.problem.xl, self.problem.xu]).T\n",
        "\n",
        "    def sample_lhs(self, n_points: int, seed: int = 42):\n",
        "        sampler = qmc.LatinHypercube(d=self.dim, seed=seed)\n",
        "        sample = sampler.random(n_points)\n",
        "        return qmc.scale(sample, self.bounds[:,0], self.bounds[:,1])\n",
        "\n",
        "    def evaluate(self, X: np.ndarray):\n",
        "        return self.problem.evaluate(X)\n",
        "\n",
        "    def inject_outliers(self, X, Y, frac: float = 0.05):\n",
        "        \"\"\"Inject outliers into Y (output). Returns noisy Y and indices of injected outliers.\"\"\"\n",
        "        n_outliers = max(1, int(frac * X.shape[0]))\n",
        "        idx = np.random.choice(X.shape[0], n_outliers, replace=False)\n",
        "        Y_out = Y.copy()\n",
        "        scale = np.std(Y, axis=0) * 10.0\n",
        "        if Y_out.ndim == 1:\n",
        "            Y_out[idx] = Y_out[idx] + np.random.normal(0, scale, size=n_outliers)\n",
        "        else:\n",
        "            Y_out[idx, 0] = Y_out[idx, 0] + np.random.normal(0, scale, size=n_outliers)\n",
        "        return Y_out, idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class StatisticalOutlierDetection:\n",
        "    def z_score(self, data, threshold: float = 3.0):\n",
        "        z_scores = np.abs(stats.zscore(data, axis=0))\n",
        "        scores = np.max(z_scores, axis=1)\n",
        "        return scores > threshold, scores\n",
        "\n",
        "    def iqr(self, data, factor: float = 1.5):\n",
        "        Q1 = np.percentile(data, 25, axis=0)\n",
        "        Q3 = np.percentile(data, 75, axis=0)\n",
        "        IQR = Q3 - Q1\n",
        "        lower = Q1 - factor * IQR\n",
        "        upper = Q3 + factor * IQR\n",
        "        mask = np.any((data < lower) | (data > upper), axis=1)\n",
        "        dist = np.max(np.maximum(0, data - upper) + np.maximum(0, lower - data), axis=1)\n",
        "        return mask, dist\n",
        "\n",
        "    def leverage(self, X, threshold: float = None):\n",
        "        if X.ndim == 1:\n",
        "            X = X.reshape(-1, 1)\n",
        "        X_design = np.column_stack([np.ones(X.shape[0]), X])\n",
        "        H = X_design @ np.linalg.pinv(X_design.T @ X_design) @ X_design.T\n",
        "        leverages = np.diag(H)\n",
        "        if threshold is None:\n",
        "            threshold = 2 * X_design.shape[1] / X_design.shape[0]\n",
        "        return leverages > threshold, leverages\n",
        "\n",
        "    def cooks_distance(self, X, y, threshold: float = None):\n",
        "        if X.ndim == 1:\n",
        "            X = X.reshape(-1, 1)\n",
        "        y = y.ravel()\n",
        "        model = LinearRegression().fit(X, y)\n",
        "        y_pred = model.predict(X)\n",
        "        residuals = y - y_pred\n",
        "        X_design = np.column_stack([np.ones(X.shape[0]), X])\n",
        "        H = X_design @ np.linalg.pinv(X_design.T @ X_design) @ X_design.T\n",
        "        leverages = np.diag(H)\n",
        "        p = X_design.shape[1]\n",
        "        n = X_design.shape[0]\n",
        "        mse = np.sum(residuals**2) / max(1, (n - p))\n",
        "        cooks_d = (residuals**2 / (p * mse)) * (leverages / (1 - leverages)**2)\n",
        "        if threshold is None:\n",
        "            threshold = 4 / n\n",
        "        return cooks_d > threshold, cooks_d\n",
        "\n",
        "    def mahalanobis(self, X, threshold: float = None):\n",
        "        cov = EmpiricalCovariance().fit(X)\n",
        "        m_dist = cov.mahalanobis(X)\n",
        "        if threshold is None:\n",
        "            # Use a high percentile as a generic cutoff; ROC will use the full score anyway\n",
        "            threshold = np.percentile(m_dist, 97.5)\n",
        "        return m_dist > threshold, m_dist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MLOutlierDetection:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.scaler = StandardScaler()\n",
        "\n",
        "    def elliptic_envelope(self, X, contamination: float = 0.1):\n",
        "        model = EllipticEnvelope(contamination=contamination, random_state=42)\n",
        "        pred = model.fit_predict(X)\n",
        "        return pred == -1, -model.decision_function(X)\n",
        "\n",
        "    def isolation_forest(self, X, contamination: float = 0.1):\n",
        "        model = IsolationForest(contamination=contamination, random_state=42)\n",
        "        pred = model.fit_predict(X)\n",
        "        return pred == -1, -model.decision_function(X)\n",
        "\n",
        "    def lof(self, X, contamination: float = 0.1, n_neighbors: int = 20):\n",
        "        model = LocalOutlierFactor(contamination=contamination, n_neighbors=n_neighbors)\n",
        "        pred = model.fit_predict(X)\n",
        "        return pred == -1, -model.negative_outlier_factor_\n",
        "\n",
        "    def one_class_svm(self, X, nu: float = 0.1):\n",
        "        model = OneClassSVM(gamma=\"scale\", nu=nu)\n",
        "        pred = model.fit_predict(X)\n",
        "        return pred == -1, -model.decision_function(X)\n",
        "\n",
        "    def sgd_one_class_svm(self, X, nu: float = 0.1):\n",
        "        try:\n",
        "            model = SGDOneClassSVM(nu=nu, random_state=42)\n",
        "            pred = model.fit_predict(X)\n",
        "            return pred == -1, -model.decision_function(X)\n",
        "        except Exception:\n",
        "            # If not available in the local sklearn version, return blanks\n",
        "            return np.zeros(X.shape[0], dtype=bool), np.zeros(X.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa7be755",
      "metadata": {},
      "outputs": [],
      "source": [
        "y_true = {}\n",
        "y_score = {\"Z-Score\": {}, \"IQR\": {}, \"Leverage\": {}, \"Cook's Distance\": {}, \"Mahalanobis\": {},\n",
        "           \"Elliptic Envelope\": {}, \"Isolation Forest\": {}, \"LOF\": {}, \"One-Class SVM\": {}, \"SGD One-Class SVM\": {}}\n",
        "model_names = [\"Z-Score\", \"IQR\", \"Leverage\", \"Cook's Distance\", \"Mahalanobis\",\n",
        "               \"Elliptic Envelope\", \"Isolation Forest\", \"LOF\", \"One-Class SVM\", \"SGD One-Class SVM\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_detection(true_idx, pred_mask, scores, method_name):\n",
        "    y_true = np.zeros(len(pred_mask), dtype=int)\n",
        "    y_true[true_idx] = 1\n",
        "    y_pred = pred_mask.astype(int)\n",
        "\n",
        "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
        "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
        "\n",
        "    # Normalize scores to [0,1] for ROC AUC (higher = more anomalous)\n",
        "    scores = np.asarray(scores)\n",
        "    if np.max(scores) > np.min(scores):\n",
        "        scores_norm = (scores - np.min(scores)) / (np.max(scores) - np.min(scores))\n",
        "    else:\n",
        "        scores_norm = scores\n",
        "    auc = roc_auc_score(y_true, scores_norm)\n",
        "\n",
        "    print(f\"{method_name:25s} | Precision={precision:.2f}  Recall={recall:.2f}  F1={f1:.2f}  AUC={auc:.2f}\")\n",
        "    #RocCurveDisplay.from_predictions(y_true, scores_norm, name=method_name)\n",
        "    #plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "714d99f4",
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_detection2(true_idx, pred_mask, scores, method_name):\n",
        "    y_true = np.zeros(len(pred_mask), dtype=int)\n",
        "    y_true[true_idx] = 1\n",
        "    y_pred = pred_mask.astype(int)\n",
        "\n",
        "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
        "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
        "\n",
        "    # Normalize scores to [0,1] for ROC AUC (higher = more anomalous)\n",
        "    scores = np.asarray(scores)\n",
        "    if np.max(scores) > np.min(scores):\n",
        "        scores_norm = (scores - np.min(scores)) / (np.max(scores) - np.min(scores))\n",
        "    else:\n",
        "        scores_norm = scores\n",
        "    auc = roc_auc_score(y_true, scores_norm)\n",
        "\n",
        "    print(f\"{method_name:25s} | Precision={precision:.2f}  Recall={recall:.2f}  F1={f1:.2f}  AUC={auc:.2f}\")\n",
        "    \n",
        "    return y_true, scores_norm\n",
        "    #RocCurveDisplay.from_predictions(y_true, scores_norm, name=method_name)\n",
        "    #plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Rosenbrock (8D)\n",
        "\n",
        "We inject 5% output outliers. Statistical methods on `y` and joint `[X, y]`; ML methods on `[X, y]`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "999dd637",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bench = Benchmark(\"rosenbrock\", dim=8)\n",
        "N = 300\n",
        "X = bench.sample_lhs(N)\n",
        "y = bench.evaluate(X)\n",
        "y = np.asarray(y).reshape(-1)  # ensure 1D\n",
        "contamination_rate = 0.05\n",
        "y_noisy, idx = bench.inject_outliers(X, y, frac=contamination_rate)\n",
        "print(f\"Injected outliers: {len(idx)} / {N}\")\n",
        "\n",
        "stat = StatisticalOutlierDetection()\n",
        "ml = MLOutlierDetection()\n",
        "\n",
        "# Statistical on y\n",
        "mask, scores = stat.z_score(y_noisy.reshape(-1,1))\n",
        "y_score[\"Z-Score\"][bench.name] = scores\n",
        "y_true[bench.name] = np.zeros(len(mask), dtype=int)\n",
        "y_true[bench.name][idx] = 1\n",
        "evaluate_detection(idx, mask, scores, \"Z-Score\")\n",
        "\n",
        "mask, scores = stat.iqr(y_noisy.reshape(-1,1), factor=1.5)\n",
        "y_score[\"IQR\"][bench.name] = scores\n",
        "y_true[bench.name] = np.zeros(len(mask), dtype=int)\n",
        "y_true[bench.name][idx] = 1\n",
        "evaluate_detection(idx, mask, scores, \"IQR)\")\n",
        "\n",
        "# Statistical on joint [X, y]\n",
        "X_aug = np.hstack([X, y_noisy.reshape(-1,1)])\n",
        "mask, scores = stat.mahalanobis(X_aug)\n",
        "y_score[\"Mahalanobis\"][bench.name] = scores\n",
        "y_true[bench.name] = np.zeros(len(mask), dtype=int)\n",
        "y_true[bench.name][idx] = 1\n",
        "evaluate_detection(idx, mask, scores, \"Mahalanobis\")\n",
        "\n",
        "mask, scores = stat.leverage(X)\n",
        "y_score[\"Leverage\"][bench.name] = scores\n",
        "y_true[bench.name] = np.zeros(len(mask), dtype=int)\n",
        "y_true[bench.name][idx] = 1\n",
        "evaluate_detection(idx, mask, scores, \"Leverage\")\n",
        "\n",
        "mask, scores = stat.cooks_distance(X, y_noisy)\n",
        "y_score[\"Cook's Distance\"][bench.name] = scores\n",
        "y_true[bench.name] = np.zeros(len(mask), dtype=int)\n",
        "y_true[bench.name][idx] = 1\n",
        "evaluate_detection(idx, mask, scores, \"Cook's Distance\")\n",
        "\n",
        "# ML on joint [X, y]\n",
        "data_scaled = ml.scaler.fit_transform(X_aug)\n",
        "X_aug = data_scaled\n",
        "mask, scores = ml.elliptic_envelope(X_aug, contamination=0.05)\n",
        "y_score[\"Elliptic Envelope\"][bench.name] = scores\n",
        "y_true[bench.name] = np.zeros(len(mask), dtype=int)\n",
        "y_true[bench.name][idx] = 1\n",
        "evaluate_detection(idx, mask, scores, \"Elliptic Envelope\")\n",
        "\n",
        "mask, scores = ml.isolation_forest(X_aug, contamination=0.05)\n",
        "y_score[\"Isolation Forest\"][bench.name] = scores\n",
        "y_true[bench.name] = np.zeros(len(mask), dtype=int)\n",
        "y_true[bench.name][idx] = 1\n",
        "evaluate_detection(idx, mask, scores, \"Isolation Forest\")\n",
        "\n",
        "mask, scores = ml.lof(X_aug, contamination=0.05)\n",
        "y_score[\"LOF\"][bench.name] = scores\n",
        "y_true[bench.name] = np.zeros(len(mask), dtype=int)\n",
        "y_true[bench.name][idx] = 1\n",
        "evaluate_detection(idx, mask, scores, \"LOF\")\n",
        "\n",
        "mask, scores = ml.one_class_svm(X_aug, nu=0.05)\n",
        "y_score[\"One-Class SVM\"][bench.name] = scores\n",
        "y_true[bench.name] = np.zeros(len(mask), dtype=int)\n",
        "y_true[bench.name][idx] = 1\n",
        "evaluate_detection(idx, mask, scores, \"One-Class SVM\")\n",
        "\n",
        "mask, scores = ml.sgd_one_class_svm(X_aug, nu=0.05)\n",
        "y_score[\"SGD One-Class SVM\"][bench.name] = scores\n",
        "y_true[bench.name] = np.zeros(len(mask), dtype=int)\n",
        "y_true[bench.name][idx] = 1\n",
        "evaluate_detection(idx, mask, scores, \"SGD One-Class SVM\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50566209",
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "cols = 2\n",
        "pos_label = 0  # mean 0 belongs to positive class\n",
        "datasets_names = y_true.keys()\n",
        "rows = math.ceil(len(datasets_names) / cols)\n",
        "\n",
        "fig, axs = plt.subplots(nrows=rows, ncols=cols, squeeze=False, figsize=(10, rows * 4))\n",
        "\n",
        "for ax, dataset_name in zip(axs.ravel(), datasets_names):\n",
        "    for model_idx, model_name in enumerate(model_names):\n",
        "        display = RocCurveDisplay.from_predictions(\n",
        "            y_true[dataset_name],\n",
        "            y_score[model_name][dataset_name],\n",
        "            pos_label=pos_label,\n",
        "            name=model_name,\n",
        "            ax=ax,\n",
        "            plot_chance_level=(model_idx == len(model_names) - 1),\n",
        "            chance_level_kw={\"linestyle\": \":\"},\n",
        "        )\n",
        "    ax.set_title(dataset_name)\n",
        "_ = plt.tight_layout(pad=2.0) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Rosenbrock (25D)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bench = Benchmark(\"rosenbrock\", dim=25)\n",
        "N = 500\n",
        "X = bench.sample_lhs(N)\n",
        "y = bench.evaluate(X)\n",
        "y = np.asarray(y).reshape(-1)\n",
        "y_noisy, idx = bench.inject_outliers(X, y, frac=0.05)\n",
        "print(f\"Injected outliers: {len(idx)} / {N}\")\n",
        "\n",
        "stat = StatisticalOutlierDetection()\n",
        "ml = MLOutlierDetection()\n",
        "\n",
        "# Statistical on y\n",
        "mask, scores = stat.z_score(y_noisy.reshape(-1,1))\n",
        "evaluate_detection(idx, mask, scores, \"Z-Score (on y)\")\n",
        "\n",
        "mask, scores = stat.iqr(y_noisy.reshape(-1,1), factor=1.5)\n",
        "evaluate_detection(idx, mask, scores, \"IQR (on y)\")\n",
        "\n",
        "# Statistical on joint [X, y]\n",
        "X_aug = np.hstack([X, y_noisy.reshape(-1,1)])\n",
        "mask, scores = stat.mahalanobis(X_aug)\n",
        "evaluate_detection(idx, mask, scores, \"Mahalanobis (on [X,y])\")\n",
        "\n",
        "mask, scores = stat.leverage(X)\n",
        "evaluate_detection(idx, mask, scores, \"Leverage (on X)\")\n",
        "\n",
        "mask, scores = stat.cooks_distance(X, y_noisy)\n",
        "evaluate_detection(idx, mask, scores, \"Cook's Distance (y~X)\")\n",
        "\n",
        "# ML on joint [X, y]\n",
        "mask, scores = ml.elliptic_envelope(X_aug, contamination=0.05)\n",
        "evaluate_detection(idx, mask, scores, \"Elliptic Envelope ([X,y])\")\n",
        "\n",
        "mask, scores = ml.isolation_forest(X_aug, contamination=0.05)\n",
        "evaluate_detection(idx, mask, scores, \"Isolation Forest ([X,y])\")\n",
        "\n",
        "mask, scores = ml.lof(X_aug, contamination=0.05)\n",
        "evaluate_detection(idx, mask, scores, \"LOF ([X,y])\")\n",
        "\n",
        "mask, scores = ml.one_class_svm(X_aug, nu=0.05)\n",
        "evaluate_detection(idx, mask, scores, \"One-Class SVM ([X,y])\")\n",
        "\n",
        "mask, scores = ml.sgd_one_class_svm(X_aug, nu=0.05)\n",
        "evaluate_detection(idx, mask, scores, \"SGD One-Class SVM ([X,y])\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Kursawe (3D, 2 objectives)\n",
        "We use the **first objective** as `y`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bench = Benchmark(\"kursawe\")\n",
        "N = 300\n",
        "X = bench.sample_lhs(N)\n",
        "F = bench.evaluate(X)\n",
        "y = np.asarray(F)[:, 0]  # first objective\n",
        "y_noisy, idx = bench.inject_outliers(X, y, frac=0.05)\n",
        "print(f\"Injected outliers: {len(idx)} / {N}\")\n",
        "\n",
        "stat = StatisticalOutlierDetection()\n",
        "ml = MLOutlierDetection()\n",
        "\n",
        "# Statistical on y\n",
        "mask, scores = stat.z_score(y_noisy.reshape(-1,1))\n",
        "evaluate_detection(idx, mask, scores, \"Z-Score (on y)\")\n",
        "\n",
        "mask, scores = stat.iqr(y_noisy.reshape(-1,1), factor=1.5)\n",
        "evaluate_detection(idx, mask, scores, \"IQR (on y)\")\n",
        "\n",
        "# Statistical on joint [X, y]\n",
        "X_aug = np.hstack([X, y_noisy.reshape(-1,1)])\n",
        "mask, scores = stat.mahalanobis(X_aug)\n",
        "evaluate_detection(idx, mask, scores, \"Mahalanobis (on [X,y])\")\n",
        "\n",
        "mask, scores = stat.leverage(X)\n",
        "evaluate_detection(idx, mask, scores, \"Leverage (on X)\")\n",
        "\n",
        "mask, scores = stat.cooks_distance(X, y_noisy)\n",
        "evaluate_detection(idx, mask, scores, \"Cook's Distance (y~X)\")\n",
        "\n",
        "# ML on joint [X, y]\n",
        "mask, scores = ml.elliptic_envelope(X_aug, contamination=0.05)\n",
        "evaluate_detection(idx, mask, scores, \"Elliptic Envelope ([X,y])\")\n",
        "\n",
        "mask, scores = ml.isolation_forest(X_aug, contamination=0.05)\n",
        "evaluate_detection(idx, mask, scores, \"Isolation Forest ([X,y])\")\n",
        "\n",
        "mask, scores = ml.lof(X_aug, contamination=0.05)\n",
        "evaluate_detection(idx, mask, scores, \"LOF ([X,y])\")\n",
        "\n",
        "mask, scores = ml.one_class_svm(X_aug, nu=0.05)\n",
        "evaluate_detection(idx, mask, scores, \"One-Class SVM ([X,y])\")\n",
        "\n",
        "mask, scores = ml.sgd_one_class_svm(X_aug, nu=0.05)\n",
        "evaluate_detection(idx, mask, scores, \"SGD One-Class SVM ([X,y])\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sphere (8D)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bench = Benchmark(\"sphere\", dim=8)\n",
        "N = 300\n",
        "X = bench.sample_lhs(N)\n",
        "y = bench.evaluate(X)\n",
        "y = np.asarray(y).reshape(-1)\n",
        "y_noisy, idx = bench.inject_outliers(X, y, frac=0.05)\n",
        "print(f\"Injected outliers: {len(idx)} / {N}\")\n",
        "\n",
        "stat = StatisticalOutlierDetection()\n",
        "ml = MLOutlierDetection()\n",
        "\n",
        "# Statistical on y\n",
        "mask, scores = stat.z_score(y_noisy.reshape(-1,1))\n",
        "evaluate_detection(idx, mask, scores, \"Z-Score (on y)\")\n",
        "\n",
        "mask, scores = stat.iqr(y_noisy.reshape(-1,1), factor=1.5)\n",
        "evaluate_detection(idx, mask, scores, \"IQR (on y)\")\n",
        "\n",
        "# Statistical on joint [X, y]\n",
        "X_aug = np.hstack([X, y_noisy.reshape(-1,1)])\n",
        "mask, scores = stat.mahalanobis(X_aug)\n",
        "evaluate_detection(idx, mask, scores, \"Mahalanobis (on [X,y])\")\n",
        "\n",
        "mask, scores = stat.leverage(X)\n",
        "evaluate_detection(idx, mask, scores, \"Leverage (on X)\")\n",
        "\n",
        "mask, scores = stat.cooks_distance(X, y_noisy)\n",
        "evaluate_detection(idx, mask, scores, \"Cook's Distance (y~X)\")\n",
        "\n",
        "# ML on joint [X, y]\n",
        "mask, scores = ml.elliptic_envelope(X_aug, contamination=0.05)\n",
        "evaluate_detection(idx, mask, scores, \"Elliptic Envelope ([X,y])\")\n",
        "\n",
        "mask, scores = ml.isolation_forest(X_aug, contamination=0.05)\n",
        "evaluate_detection(idx, mask, scores, \"Isolation Forest ([X,y])\")\n",
        "\n",
        "mask, scores = ml.lof(X_aug, contamination=0.05)\n",
        "evaluate_detection(idx, mask, scores, \"LOF ([X,y])\")\n",
        "\n",
        "mask, scores = ml.one_class_svm(X_aug, nu=0.05)\n",
        "evaluate_detection(idx, mask, scores, \"One-Class SVM ([X,y])\")\n",
        "\n",
        "mask, scores = ml.sgd_one_class_svm(X_aug, nu=0.05)\n",
        "evaluate_detection(idx, mask, scores, \"SGD One-Class SVM ([X,y])\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
